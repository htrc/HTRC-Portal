@(user: User) @main("Extracted Features Dataset", user) {

<!-- Highlight.js -->
<link rel="stylesheet" href="@routes.Assets.at(" stylesheets/highlight.default.css ")">
<script src="@routes.Assets.at(" javascripts/highlight.pack.js ")"></script>
<script>
  hljs.initHighlightingOnLoad();
</script>
<div class="container container-panel">
    <div class="container">
  <div class="row">
    <div class="col-md-12">

      <h1 id="page-level-features-from-the-htrc">HTRC Extracted Features Dataset
        <br><small>Page-level features from 4.8 million volumes [v.0.2]</small>
      </h1>

    </div>
  </div>
  <!-- End Header Row-->
  <div class="row" style="padding-right: 20px;">
    <div class="col-md-9">
      <p class="text-info">Note that this is a
        <strong>beta</strong> data release. Please send feedback to
        <span class="contact">(Need javascript to show)</span>.</p>


      <p>A great deal of useful research can be performed non-consumptively with pre-extracted features. For this reason, we've prepared a data export of features for the public domain volumes of the HathiTrust Digital Library.</p>
      <p>
        <em>Features</em> are notable or informative characteristics of the text. Also, we have processed a number of useful features, including part-of-speech tagged token counts, header and footer identification, and various line-level information. These are provided <em>per-page</em>. Providing token information at the page-level makes it possible to separate text from paratext; for instance, a researcher may use the information to identify publishers' ads at the back of a book. For cleaner text, headers and footers are also identified distinctly from page content. The specific features that we extract for each page are described in more detail below.</p>
      <p>The most useful extracted feature that we are provide is the token (unigram) count, on a per-page basis. Term counts are specific to the part-of-speech usage for that term, so that a term used as both a noun and a verb, for example, will have separate counts provided for both these modalities of its use. We also include line information, such as the number of lines with text on each page, and a count of characters that start and end lines on each page. This information can illuminate
        genre and volume structure: for instance, it helps distinguish poetry from prose, or body text from an index.</p>
      <p>The present release is a beta release, and we would love to hear about how you use it, or what else you would like to see!</p>
      <p>Review the documentation below or jump straight to the <a href="#downloads">downloads</a>.</p>

      <h3>Attribution</h3>
      <p>This feature dataset is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>. For attribution, please use the following citation:</p>
      <p class="text-info">
      <span class="glyphicon glyphicon-bookmark" aria-hidden="true"></span>  
      Boris Capitanu, Ted Underwood, Peter Organisciak, Sayan Bhattacharyya, Loretta Auvil, Colleen Fallaw, J. Stephen Downie (2015). <em>Extracted Feature Dataset from 4.8 Million HathiTrust Digital Library Public Domain Volumes</em>. [Dataset]. HathiTrust Research Center, doi:10.13012/j8td9v7m.
      </p>
      </div>
    <!-- END intro col -->

    <div class="col-md-3" >
      <h3>Data Stats</h3>
      <table class="table">
        <tr>
          <td># of volumes</td>
          <td>4,801,237</td>
        </tr>
        <tr>
          <td># of pages</td>
          <td>1,825,317,899</td>
        </tr>
        <tr>
          <td>Median pages/volume</td>
          <td>330</td>
        </tr>

      </table>
      <p><a href="http://www.hathitrust.org/datasets">More information about HathiTrust datasets.</a>
      </p>
    </div>
    <!--End About the Data-->

  </div>
  <div class="row" style="padding-right: 20px;">
    <div class="col-md-12" >
      <h1>Feature File Documentation</h1>
      <p>The HTRC Extracted Features provides two JSON files for each volume: a basic features files and an advanced features file. For most users, the basic features should suffice. Both files include the volume metadata.</p>

    </div>
  </div>

  <div class="row" style="padding-right: 20px;">
    <div class="col-md-3">
      <h2 id="documentation-for-metadata">Metadata</h2>
      <p>A small amount of bibliographic metadata for identifying the volume is included in this dataset. See also: <a href="#metadata">“Where can I find detailed bibliographic metadata?”</a>.</p>
      <p>
        <strong>id</strong>: A unique identifier for the current volume. This is the same identifier used in the HathiTrust and HathiTrust Research Center corpora.</p>
      <p>
        <strong>schemaVersion</strong>: A version identifier for the format and structure of this metadata object.
        <em>metadata.schemaVersion</em> is separate from
        <em>features.schemaVersion</em> below.</p>
      <p>
        <strong>dateCreated</strong>: The time this metadata object was processed.
        <em>metadata.dateCreated</em> is not necessarily the same as the
        <em>features.dataCreated</em> below.</p>
      <p>
        <strong>title</strong>: Title of the volume.</p>
      <p>
        <strong>pubDate</strong>: The publication year.</p>
      <p>
        <strong>language</strong>: The primary language of the volume.</p>
      <p>
        <strong>htBibUrl</strong>: The HathiTrust Bibliographic API call for the volume.</p>
      <p>
        <strong>handleUrl</strong>: The persistent identifier for the given volume.</p>
      <p>
        <strong>oclc</strong>: The array of <a href="https://oclc.org/en-US/home.html">OCLC</a> number(s).</p>
      <p>
        <strong>imprint</strong>: The place of publication, publisher, and publication date of the given volume.</p>

    </div>
    <!--End Metadata-->

    <div class="col-md-6">
      <!-- START BASIC DOCUMENTATION -->
      <h2 id="documentation-for-basic-extracted-features">Basic Features</h2>
      <h3 id="features">Volume-Level Features</h3>
      <p>
        <strong>schemaVersion</strong>: A version identifier for the format and structure of the feature data (HTRC generated).</p>
      <p>
        <strong>dateCreated</strong>: The time the batch of metadata was processed and recorded (HTRC generated).</p>
      <p>
        <strong>pageCount</strong>: The number of pages in the volume.</p>
      <p>
        <strong>pages</strong>: An array of JSON objects, each representing a page of the volume.</p>
      <h3 id="page">Pagei-Level Features</h3>
      <p>Pages are contained within volumes, they have a sequence number, and information about their header, body, and footer.</p>
      <h4 id="page-level-information">Page-level information</h4>
      <p>
        <strong>seq</strong>: The sequence number. <a href="#page-id">More details on this value.</a>.</p>
      <p>
        <strong>tokenCount</strong>: The total number of tokens on the page.</p>
      <p>
        <strong>lineCount</strong>: The total number of non-empty lines on the page.</p>
      <p>
        <strong>emptyLineCount</strong>: The total number of empty lines on the page.</p>
      <p>
        <strong>sentenceCount</strong>: Total number of sentences identified on the page using OpenNLP. <a href="#token-parse">Details on parsing</a>.</p>
      <p>
        <strong>languages</strong>: Automatically inferred language likelihood for the page, Shuyo Nakatani's <a href="https://code.google.com/p/language-detection/">Language Detection</a> library. <a href="https://code.google.com/p/language-detection/wiki/LanguageList">Language code reference</a>.</p>
      <h4 id="header-body-and-footer-information">Header, Body, and Footer information</h4>
      <p>The fields for
        <em>header</em>,
        <em>body</em>, and
        <em>footer</em> are the same, but pertain to different parts of the page. <a href="#header-q">Read about the differences between the sections</a>.</p>
      <p>
        <strong>tokenCount</strong>: The total number of tokens in this page section.</p>
      <p>
        <strong>lineCount</strong>: The number of lines containing characters of any kind in this page section. This pertains to the layout of the page; for sentence counts, see the
        <em>sentenceCount</em> field.</p>
      <p>
        <strong>emptyLineCount</strong>: The number of lines without text in this page section.</p>
      <p>
        <strong>sentenceCount</strong>: The number of sentences found in the text in this page section, parsed using OpenNLP.</p>
      <p>
        <strong>tokenPosCount</strong>: An unordered list of all tokens (characterized by part of speech using OpenNLP), and their corresponding frequency counts, in this page section. Tokens are case-sensitive, so a capitalized “Rose” is shown as a separate
        token. There will be separate counts, for instance, for “rose” (noun) and “rose” (verb). Words separated by a hyphen across a line break are rejoined. No other data cleaning or OCR correction was performed. <a href="#token-parse">Details on POS parsing and types of tags used</a>.
    </div>
    <!-- End basic documentation -->


    <div id="advanced-documentation" class="col-md-3" >
      <h2>Advanced Features</h2>
      <p>The advanced features data provides additional page-level features, while including the same volume-level that is included with the basic features set.</p>
      <h3 id="features-1">Volume-Level Features</h3>
      <p>The features extracted from the content of the volume.</p>
      <p>
        <strong>schemaVersion</strong>: A version identifier for the format and structure of the feature data (HTRC generated).</p>
      <p>
        <strong>dateCreated</strong>: The time the batch of metadata was processed and recorded (HTRC generated).</p>
      <p>
        <strong>pageCount</strong>: The number of pages in the volume.</p>
      <p>
        <strong>pages</strong>: An array of JSON objects, each representing a page of the volume.</p>
      <h3 id="page-1">Page-Level Features</h3>
      <p>Pages are contained within volumes, they have a sequence number, and information about their header, body, and footer.</p>
      <h4 id="page-level-information-1">Page-level information</h4>
      <p>
        <strong>seq</strong>: The sequence number.</p>
      <p>
        <strong>beginLineChars</strong>: Frequency counts of non-whitespace characters at the starts of lines. Characters with zero counts are not shown.</p>
      <p>
        <strong>endLineChars</strong>: Count of the last character on each line in this page section (ignoring whitespace).</p>
      <p>
        <strong>capAlphaSeq</strong>: (body only) The longest length of the alphabetical sequence of capital characters starting a line.</p>





    </div>
    <!--End advanced documentation -->
  </div>
  <!-- End row-->

  <div class="row" style="padding-right: 20px;">
      <hr />
    <div class="col-md-12" >
      <h2 id="downloads">Get the Data</h2>

      <p>The data is accessible using rsync. Rsync should be installed already on your Mac or Linux system; Windows users can use it through <a href="https://cygwin.com/install.html">Cygwin</a>.</p>

      <h3 id="sample-files">Sample Files</h3>
      <p>A sample of 100 extracted feature files is available for download through your browser: <a href="http://data.sharc.hathitrust.org/data/EF/sample.tar">sample.tar</a>.</p>
      <p>Also, thematic collections are available to download: <a href="http://data.sharc.hathitrust.org/data/EF/docsouth_samples.tar">DocSouth</a> (87 volumes), <a href="http://data.sharc.hathitrust.org/data/EF/EEBO_samples.tar">EEBO</a> (355 volumes),
        <a href="http://data.sharc.hathitrust.org/data/EF/ECCO_samples.tar">ECCO</a> (505 volumes).</p>
      <h3 id="rsync">Rsync</h3>

      <p>Rsync will download each feature file individually, following a pairtree directory structure.</p>
      <p>To sync all the basic feature files:</p>
        <div class="row" style="padding-left: 28px;">
            <pre class="col-xs-8">rsync -av data.sharc.hathitrust.org::pd-features/basic/ .</pre>
        </div>


      <p>
        <b><em>Note that this data is 1.19 Terabytes!</em> Only download all of it if you know what you are doing.</b></p>
      <p>To sync all the advanced feature files:</p>
        <div class="row" style="padding-left: 28px;">
            <pre class="col-xs-8">rsync -av data.sharc.hathitrust.org::pd-features/advanced/ .</pre>
        </div>

      <p>A randomly sorted listing of all the basic files is available in the following location:</p>
        <div class="row" style="padding-left: 28px;">
            <pre class="col-xs-8">rsync -azv data.sharc.hathitrust.org::pd-features/listing/pd-basic-file-listing.txt .</pre>
        </div>

      There is also an advanced file listing at
        <div class="row" style="padding-left: 28px;">
            <pre class="col-xs-8">pd-features/listing/pd-advanced-file-listing.txt</pre>
        </div>
      <p>Users hoping for a more flexible file listings can use rsync's --list-only flag.</p>
      <p>To rsync only the files in a given text file:</p>
        <div class="row" style="padding-left: 28px;">
            <pre class="col-xs-8">rsync -av --files-from FILE.TXT data.sharc.hathitrust.org::pd-features/ .</pre>
        </div>

      <h4 id="file-names">File names</h4>
      <p>Volume feature files use the volume's ID, with the following characters substituted:
        <em>:</em> to
        <em>+</em>, and
        <em>/</em> to
        <em>=</em>. This means that any list of HathiTrust public domain files can be used to download the corresponding feature files.</p>

	<h3 id="workset-download">Workset Download</h3>
	To download the Extracted Features data for a specific workset in the HTRC Portal, there is an algorithm that generates the Rsync download script: <a href="https://htrc2.pti.indiana.edu/viewalgorithm?algorithmName=EF_Rsync_Script_Generator">EF Rsync Script Generator</a>.
    </div>

  </div>
  <div class="row" style="padding-right: 20px;">
    <div class="col-md-12">
      <!-- START DOCUMENTATION/QUESTION -->




      <h2 id="questions">Questions</h2>
      <h3 id="token-parse">How are tokens parsed?</h3>
      <p>Hyphenation of tokens at end of line was corrected using custom code. <a href="http://opennlp.apache.org/">Apache OpenNLP</a> was used for sentence segmentation, tokenization, and part of speech (POS) tagging. No additional data cleaning or OCR correction was performed.</p>
      <p>OpenNLP uses <a href="http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html">the Penn Treebank POS tags</a>.</p>
      <h3 id="page-id">Can I use the page sequence as a unique identifier?</h3>
      <p>The
        <em>seq</em> value is always sequential from the start. Each scanned page of a volume has a unique sequence number, but it is specific to the <em>current</em> version of the full text. In theory, updates to the OCR that add or remove pages will change the sequence. The practical likelihood of changes in the sequence is low, but uses of the page as an id should be cautious.</p>
      <p>A future release of this data will include persistent page identifiers that remain unchanged even when page sequence changes.</p>
      <h3 id="metadata">Where is the bibliographic metadata? Who wrote the book?; When was it published, etc.?</h3>
      <p>This dataset is foremost an extracted features dataset, with minimal metadata included as a convenience. For additional metadata information, i.e. subject classifications, etc., HT offers <a href="http://www.hathitrust.org/hathifiles">Hathifiles</a>,
        which can be paired to our feature dataset through the volume
        <em>id</em> field.</p>
      <p>The metadata that
        <em>is</em> included in this data includes MARC metadata from HathiTrust and additional information from Hathifiles:</p>
      <ul>
        <li>imprint: 260a from HathiTrust MARC record, 260b and 260c from Hathifiles.</li>
        <li>language: MARC control field 008 from Hathifiles.</li>
        <li>pubDate: extracted from Hathifiles. See also: <a href="http://www.hathitrust.org/bib_rights_determination">details on HathiTrust's rights-determination</a>.</li>
        <li>oclc: extracted from Hathifiles.</li>
      </ul>
      <p>Additionally, schemaVersion and dateCreated are specific to this feature dataset.</p>
      <h3 id="eol">What do I do with beginning- or end-of-line characters?</h3>
      <p>The characters at the start and end of a line can be used to differentiate text from <a href="http://en.wikipedia.org/wiki/Paratext">paratext</a> at a page level. For instance, index lines tend to begin with capitalized letters and end with numbers.
        Likewise, lines in a table of contents can be identified through arabic or roman numerals at the start of a line.</p>
      <h3 id="header-q">What is the difference between the header, body, and footer sections?</h3>
      <p>Because repeated headers and footers can distort word counts in a document, but also help identify document parts, we attempt to identify repeated lines at the top or bottom of a page and provide separate token counts for those forms of paratext.
        The “header” and “footer” sections will also include tokens that are page numbers, catchwords, or other short lines at the very top or bottom of a page. Users can of course ignore these divisions by aggregating the token counts for header, body,
        and footer sections.</p>




    </div>
    <!-- End documentation col-->
  </div>
  <!-- End documentation row-->

  <div class="row-fluid"  style="padding-right: 20px;">
      <hr />
    <div class="col-md-4">
      <h4>Contact Us</h4>
      <p class='contact'>Need JavaScript to show</p>



    </div>
    <div class="col-md-4">
      <h4>Tools</h4>
      <p class="text-muted">If you've built tools or scripts for processing our data, let us know and we'll feature them here!</p>
    </div>
    <div class="col-md-4">
      <h4>Projects</h4>
      <p class="text-muted">Let us know about your projects and we'll link to them here.</p>
    </div>
  </div>

</div>
</div>
<!-- End body container-->
<script>
  $(document).ready(function() {
    var a = "@@";
    $(".contact").text("htrc-support-l" + a + "list.indiana.edu");
  });
</script>

<!-- Google Analytics tracking code -->
<!--<script>-->
  <!--(function(i, s, o, g, r, a, m) {-->
    <!--i['GoogleAnalyticsObject'] = r;-->
    <!--i[r] = i[r] || function() {-->
      <!--(i[r].q = i[r].q || []).push(arguments)-->
    <!--}, i[r].l = 1 * new Date();-->
    <!--a = s.createElement(o),-->
      <!--m = s.getElementsByTagName(o)[0];-->
    <!--a.async = 1;-->
    <!--a.src = g;-->
    <!--m.parentNode.insertBefore(a, m)-->
  <!--})(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');-->

  <!--ga('create', 'UA-42842720-3', 'illinois.edu');-->
  <!--ga('send', 'pageview');-->
<!--</script>-->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-42842720-1', 'indiana.edu');
  ga('send', 'pageview');
</script>



}
